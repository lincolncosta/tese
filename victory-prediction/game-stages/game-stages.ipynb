{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def qtd_eventos(integer):\n",
    "    return int((400 - integer) / 2)\n",
    "\n",
    "def preprocess_input(X,y):\n",
    "    X = X.copy()\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8,stratify=y)\n",
    "    scaler = StandardScaler()   \n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train,X_test,y_train,y_test,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3170: DtypeWarning: Columns (116,117,118,119,120,121,122,123,124,125,126,127) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/crawler/unified-events-statistics-with-kills.csv')\n",
    "\n",
    "qtd_eventos = list(map(qtd_eventos, df.isnull().sum(axis=1).tolist()))\n",
    "df['qtd_eventos'] = qtd_eventos\n",
    "df = df.replace([\n",
    "    'BLUE: kill',\n",
    "    'BLUE: plate',\n",
    "    'BLUE: first_blood',\n",
    "    'BLUE: dragon',\n",
    "    'BLUE: herald',\n",
    "    'BLUE: first_tower_top',\n",
    "    'BLUE: first_tower_mid',\n",
    "    'BLUE: first_tower_bot',\n",
    "    'BLUE: second_tower_top',\n",
    "    'BLUE: second_tower_mid',\n",
    "    'BLUE: second_tower_bot',\n",
    "    'BLUE: third_tower_top',\n",
    "    'BLUE: third_tower_mid',\n",
    "    'BLUE: third_tower_bot',\n",
    "    'BLUE: inhibitor_top',\n",
    "    'BLUE: inhibitor_mid',\n",
    "    'BLUE: inhibitor_bot',\n",
    "    'BLUE: baron',\n",
    "    'BLUE: elder_dragon',\n",
    "    'BLUE: nexus_tower',\n",
    "    'BLUE: nexus',\n",
    "    'RED: kill',\n",
    "    'RED: plate',\n",
    "    'RED: first_blood',\n",
    "    'RED: dragon',\n",
    "    'RED: herald',\n",
    "    'RED: first_tower_top',\n",
    "    'RED: first_tower_mid',\n",
    "    'RED: first_tower_bot',\n",
    "    'RED: second_tower_top',\n",
    "    'RED: second_tower_mid',\n",
    "    'RED: second_tower_bot',\n",
    "    'RED: third_tower_top',\n",
    "    'RED: third_tower_mid',\n",
    "    'RED: third_tower_bot',\n",
    "    'RED: inhibitor_top',\n",
    "    'RED: inhibitor_mid',\n",
    "    'RED: inhibitor_bot',\n",
    "    'RED: baron',\n",
    "    'RED: elder_dragon',\n",
    "    'RED: nexus_tower',\n",
    "    'RED: nexus'], range(1,43))\n",
    "\n",
    "df = df.drop(['game'],axis=1)\n",
    "df = df.fillna(0)\n",
    "df = df.astype(int)\n",
    "y = df['result'].copy()\n",
    "X = df.drop(['golId','result','qtd_eventos'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time: 7.6569136619567875 (+/- 0.5860570064756998)\n",
      "score_time: 0.3426473617553711 (+/- 0.03792541358553678)\n",
      "test_Balanced Accuracy: 0.9803532012050284 (+/- 0.005187580243418611)\n",
      "test_Precision: 0.9802352640201779 (+/- 0.00519852539374372)\n",
      "test_Recall: 0.979879336600263 (+/- 0.005350485383502701)\n",
      "test_F1: 0.9798865729927364 (+/- 0.005347444803129479)\n",
      "test_AUC: 0.9960870306899411 (+/- 0.0024319403787203416)\n"
     ]
    }
   ],
   "source": [
    "# Definindo o modelo\n",
    "model = RandomForestClassifier(max_depth=50, n_estimators=600, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "# Definindo as métricas\n",
    "scoring = {\n",
    "    'Balanced Accuracy': make_scorer(balanced_accuracy_score),\n",
    "    'Precision': make_scorer(precision_score, average='weighted'),\n",
    "    'Recall': make_scorer(recall_score, average='weighted'),\n",
    "    'F1': make_scorer(f1_score, average='weighted'),\n",
    "    'AUC': make_scorer(roc_auc_score, needs_proba=True, average='weighted')\n",
    "}\n",
    "\n",
    "# Realizando a validação cruzada\n",
    "cv_results = cross_validate(model, X, y, cv=5, scoring=scoring, error_score='raise')\n",
    "\n",
    "# Extraindo os resultados\n",
    "for metric, scores in cv_results.items():\n",
    "    print(f'{metric}: {scores.mean()} (+/- {scores.std()})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>amount_events</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.982406</td>\n",
       "      <td>0.993317</td>\n",
       "      <td>0.971930</td>\n",
       "      <td>0.982502</td>\n",
       "      <td>0.996020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.972716</td>\n",
       "      <td>0.984973</td>\n",
       "      <td>0.961404</td>\n",
       "      <td>0.973038</td>\n",
       "      <td>0.993953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine (RBF Kernel)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988454</td>\n",
       "      <td>0.991377</td>\n",
       "      <td>0.986284</td>\n",
       "      <td>0.988812</td>\n",
       "      <td>0.993747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.971783</td>\n",
       "      <td>0.960084</td>\n",
       "      <td>0.988357</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.990451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3</td>\n",
       "      <td>0.980666</td>\n",
       "      <td>0.981228</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.981512</td>\n",
       "      <td>0.989751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>3</td>\n",
       "      <td>0.962914</td>\n",
       "      <td>0.967266</td>\n",
       "      <td>0.961244</td>\n",
       "      <td>0.964226</td>\n",
       "      <td>0.987494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decission Tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.923213</td>\n",
       "      <td>0.926588</td>\n",
       "      <td>0.926635</td>\n",
       "      <td>0.926472</td>\n",
       "      <td>0.923213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gaussian NB</td>\n",
       "      <td>3</td>\n",
       "      <td>0.572613</td>\n",
       "      <td>0.510319</td>\n",
       "      <td>0.273525</td>\n",
       "      <td>0.238283</td>\n",
       "      <td>0.906426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model amount_events  Balanced Accuracy  \\\n",
       "4                        Random Forest             3           0.982406   \n",
       "5         Gradient Boosting Classifier             3           0.972716   \n",
       "1  Support Vector Machine (RBF Kernel)             3           0.988454   \n",
       "6                                  KNN             3           0.971783   \n",
       "0                  Logistic Regression             3           0.980666   \n",
       "3                             Adaboost             3           0.962914   \n",
       "2                       Decission Tree             3           0.923213   \n",
       "7                          Gaussian NB             3           0.572613   \n",
       "\n",
       "   Precision    Recall  F1-Score       auc  \n",
       "4   0.993317  0.971930  0.982502  0.996020  \n",
       "5   0.984973  0.961404  0.973038  0.993953  \n",
       "1   0.991377  0.986284  0.988812  0.993747  \n",
       "6   0.960084  0.988357  0.974000  0.990451  \n",
       "0   0.981228  0.981818  0.981512  0.989751  \n",
       "3   0.967266  0.961244  0.964226  0.987494  \n",
       "2   0.926588  0.926635  0.926472  0.923213  \n",
       "7   0.510319  0.273525  0.238283  0.906426  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executions = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "  X_train,X_test,y_train,y_test,scaler = preprocess_input(X,y)\n",
    "  \n",
    "  models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=50000),\n",
    "    'Support Vector Machine (RBF Kernel)': SVC(C=100,gamma=0.001,kernel='rbf',max_iter=50000,probability=True),\n",
    "    'Decission Tree': DecisionTreeClassifier(),\n",
    "    'Adaboost': AdaBoostClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(max_depth=25,n_estimators=600,min_samples_split=2,min_samples_leaf=1),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(criterion='friedman_mse',learning_rate=0.025,loss='deviance',max_depth=4,max_features='log2',min_samples_leaf=8,min_samples_split=3, n_estimators=100,subsample=0.5),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=3),\n",
    "    'Gaussian NB': GaussianNB()\n",
    "  }\n",
    "\n",
    "  for name, model in models.items():\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "  scores_list = []\n",
    "\n",
    "  for name,model in models.items():    \n",
    "      scores_list.append({\n",
    "      'model': name,\n",
    "      'amount_events': '3',\n",
    "      'execution': i,\n",
    "      'Balanced Accuracy': balanced_accuracy_score(y_test,model.predict(X_test)),\n",
    "      'Precision':  precision_score(y_test,model.predict(X_test)),\n",
    "      'Recall': recall_score(y_test,model.predict(X_test)),\n",
    "      'F1-Score': f1_score(y_test,model.predict(X_test)),\n",
    "      'auc': roc_auc_score(y_test,model.predict_proba(X_test)[:,1])\n",
    "      })\n",
    "  # scores = pd.DataFrame(scores_list)\n",
    "  executions = executions.append(scores_list)\n",
    "\n",
    "avg_scores_list = []\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    avg_balanced_acc = 0\n",
    "\n",
    "    model_metrics = executions.loc[executions['model'] == name]\n",
    "    avg_balanced_acc = model_metrics['Balanced Accuracy'].sum() / len(model_metrics['Balanced Accuracy'])\n",
    "    avg_precision = model_metrics['Precision'].sum() / len(model_metrics['Precision'])\n",
    "    avg_recall = model_metrics['Recall'].sum() / len(model_metrics['Recall'])\n",
    "    avg_f_score = model_metrics['F1-Score'].sum() / len(model_metrics['F1-Score'])\n",
    "    avg_auc = model_metrics['auc'].sum() / len(model_metrics['auc'])\n",
    "\n",
    "    avg_scores_list.append({\n",
    "      'model': name,\n",
    "      'amount_events': '3',\n",
    "      'Balanced Accuracy': avg_balanced_acc,\n",
    "      'Precision': avg_precision,\n",
    "      'Recall': avg_recall,\n",
    "      'F1-Score': avg_f_score,\n",
    "      'auc': avg_auc\n",
    "      })\n",
    "avg_scores = pd.DataFrame(avg_scores_list)\n",
    "ordered_scores = avg_scores.sort_values(by='auc', ascending=False)\n",
    "best_model = avg_scores.sort_values(by='auc', ascending=False).iloc[0]['model']\n",
    "ordered_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>amount_events</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>3</td>\n",
       "      <td>0.678614</td>\n",
       "      <td>0.686501</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>0.748630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.679124</td>\n",
       "      <td>0.680110</td>\n",
       "      <td>0.734290</td>\n",
       "      <td>0.706100</td>\n",
       "      <td>0.748002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.667194</td>\n",
       "      <td>0.654553</td>\n",
       "      <td>0.786124</td>\n",
       "      <td>0.714308</td>\n",
       "      <td>0.742942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3</td>\n",
       "      <td>0.673647</td>\n",
       "      <td>0.679830</td>\n",
       "      <td>0.712919</td>\n",
       "      <td>0.695885</td>\n",
       "      <td>0.735933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine (RBF Kernel)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.668700</td>\n",
       "      <td>0.671830</td>\n",
       "      <td>0.720734</td>\n",
       "      <td>0.695305</td>\n",
       "      <td>0.727608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.592021</td>\n",
       "      <td>0.605395</td>\n",
       "      <td>0.633174</td>\n",
       "      <td>0.618865</td>\n",
       "      <td>0.614039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decission Tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.586099</td>\n",
       "      <td>0.603916</td>\n",
       "      <td>0.602233</td>\n",
       "      <td>0.602954</td>\n",
       "      <td>0.586099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gaussian NB</td>\n",
       "      <td>3</td>\n",
       "      <td>0.504548</td>\n",
       "      <td>0.523514</td>\n",
       "      <td>0.991388</td>\n",
       "      <td>0.685189</td>\n",
       "      <td>0.528064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model amount_events  Balanced Accuracy  \\\n",
       "3                             Adaboost             3           0.678614   \n",
       "4                        Random Forest             3           0.679124   \n",
       "5         Gradient Boosting Classifier             3           0.667194   \n",
       "0                  Logistic Regression             3           0.673647   \n",
       "1  Support Vector Machine (RBF Kernel)             3           0.668700   \n",
       "6                                  KNN             3           0.592021   \n",
       "2                       Decission Tree             3           0.586099   \n",
       "7                          Gaussian NB             3           0.504548   \n",
       "\n",
       "   Precision    Recall  F1-Score       auc  \n",
       "3   0.686501  0.710526  0.698241  0.748630  \n",
       "4   0.680110  0.734290  0.706100  0.748002  \n",
       "5   0.654553  0.786124  0.714308  0.742942  \n",
       "0   0.679830  0.712919  0.695885  0.735933  \n",
       "1   0.671830  0.720734  0.695305  0.727608  \n",
       "6   0.605395  0.633174  0.618865  0.614039  \n",
       "2   0.603916  0.602233  0.602954  0.586099  \n",
       "7   0.523514  0.991388  0.685189  0.528064  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_start = 0\n",
    "early_end = 10\n",
    "\n",
    "# Criar uma lista com o nome dos eventos e seus respectivos tempos\n",
    "eventos = ['event{}'.format(i) for i in range(1, 201)]\n",
    "tempos = ['event{}time'.format(i) for i in range(1, 201)]\n",
    "\n",
    "# Filtrar apenas os eventos que aconteceram antes de 10 minutos\n",
    "eventos_early = []\n",
    "\n",
    "for evento, tempo in zip(eventos, tempos):\n",
    "    eventos_early.append(df[(df[tempo] >= early_start) & (df[tempo] <= early_end)][evento])\n",
    "\n",
    "eventos_early.append(df[['blueTopGP','blueTopWR','blueTopKDA','blueJungleGP','blueJungleWR','blueJungleKDA','blueMidGP','blueMidWR','blueMidKDA','blueADCGP','blueADCWR','blueADCKDA','blueSupportGP','blueSupportWR','blueSupportKDA','redTopGP','redTopWR','redTopKDA','redJungleGP','redJungleWR','redJungleKDA','redMidGP','redMidWR','redMidKDA','redAdcGP','redAdcWR','redAdcKDA','redSupportGP','redSupportWR','redSupportKDA']])\n",
    "\n",
    "# Criar um novo DataFrame com os eventos que aconteceram antes de 10 minutos\n",
    "df_early = pd.concat(eventos_early, axis=1)\n",
    "df_early = df_early.fillna(0)\n",
    "df_early = df_early.astype(int)\n",
    "X_early = df_early.copy()\n",
    "\n",
    "executions = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "  X_train,X_test,y_train,y_test,scaler = preprocess_input(X_early,y)\n",
    "  \n",
    "  models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=50000),\n",
    "    'Support Vector Machine (RBF Kernel)': SVC(C=100,gamma=0.001,kernel='rbf',max_iter=50000,probability=True),\n",
    "    'Decission Tree': DecisionTreeClassifier(),\n",
    "    'Adaboost': AdaBoostClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(max_depth=25,n_estimators=600,min_samples_split=2,min_samples_leaf=1),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(criterion='friedman_mse',learning_rate=0.025,loss='deviance',max_depth=4,max_features='log2',min_samples_leaf=8,min_samples_split=3, n_estimators=100,subsample=0.5),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=3),\n",
    "    'Gaussian NB': GaussianNB()\n",
    "  }\n",
    "\n",
    "  for name, model in models.items():\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "  scores_list = []\n",
    "\n",
    "  for name,model in models.items():    \n",
    "      scores_list.append({\n",
    "      'model': name,\n",
    "      'amount_events': '3',\n",
    "      'execution': i,\n",
    "      'Balanced Accuracy': balanced_accuracy_score(y_test,model.predict(X_test)),\n",
    "      'Precision':  precision_score(y_test,model.predict(X_test)),\n",
    "      'Recall': recall_score(y_test,model.predict(X_test)),\n",
    "      'F1-Score': f1_score(y_test,model.predict(X_test)),\n",
    "      'auc': roc_auc_score(y_test,model.predict_proba(X_test)[:,1])\n",
    "      })\n",
    "  # scores = pd.DataFrame(scores_list)\n",
    "  executions = executions.append(scores_list)\n",
    "\n",
    "avg_scores_list = []\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    avg_balanced_acc = 0\n",
    "\n",
    "    model_metrics = executions.loc[executions['model'] == name]\n",
    "    avg_balanced_acc = model_metrics['Balanced Accuracy'].sum() / len(model_metrics['Balanced Accuracy'])\n",
    "    avg_precision = model_metrics['Precision'].sum() / len(model_metrics['Precision'])\n",
    "    avg_recall = model_metrics['Recall'].sum() / len(model_metrics['Recall'])\n",
    "    avg_f_score = model_metrics['F1-Score'].sum() / len(model_metrics['F1-Score'])\n",
    "    avg_auc = model_metrics['auc'].sum() / len(model_metrics['auc'])\n",
    "\n",
    "    avg_scores_list.append({\n",
    "      'model': name,\n",
    "      'amount_events': '3',\n",
    "      'Balanced Accuracy': avg_balanced_acc,\n",
    "      'Precision': avg_precision,\n",
    "      'Recall': avg_recall,\n",
    "      'F1-Score': avg_f_score,\n",
    "      'auc': avg_auc\n",
    "      })\n",
    "avg_scores = pd.DataFrame(avg_scores_list)\n",
    "ordered_scores = avg_scores.sort_values(by='auc', ascending=False)\n",
    "best_model = avg_scores.sort_values(by='auc', ascending=False).iloc[0]['model']\n",
    "ordered_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em 68.31% de das partidas, o vencedor do early é igual ao vencedor da partida.\n"
     ]
    }
   ],
   "source": [
    "# Definindo uma função para contar os eventos\n",
    "def contar_eventos(row):\n",
    "    azul = sum(1 for evento in row if 1 <= evento <= 21)\n",
    "    vermelho = sum(1 for evento in row if 22 <= evento <= 42)\n",
    "    return azul, vermelho\n",
    "\n",
    "def calcular_porcentagem(X, Y):\n",
    "    porcentagem = (X / Y) * 100\n",
    "    return porcentagem\n",
    "\n",
    "# Selecionando apenas as colunas que começam com 'event'\n",
    "colunas_event = [coluna for coluna in df_early.columns if coluna.startswith('event')]\n",
    "\n",
    "# Criando as novas colunas\n",
    "df_early['qtd_eventos_azul'], df_early['qtd_eventos_vermelho'] = zip(*df_early[colunas_event].apply(contar_eventos, axis=1))\n",
    "df_early['vencedor_early'] = df_early.apply(lambda row: 1 if row['qtd_eventos_azul'] > row['qtd_eventos_vermelho'] else 0, axis=1)\n",
    "# Exibindo o DataFrame resultante\n",
    "df_early = pd.concat([df_early, y], axis=1)\n",
    "df_early['result'] = df_early['result'].astype(int)\n",
    "\n",
    "qtd_iguais = (df_early['vencedor_early'] == df_early['result']).sum()\n",
    "resultado = calcular_porcentagem(qtd_iguais, df_early.shape[0])\n",
    "\n",
    "print(f\"Em {resultado:.2f}% de das partidas, o vencedor do early é igual ao vencedor da partida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time: 0.7798592567443847 (+/- 0.05074023625877756)\n",
      "score_time: 0.11602272987365722 (+/- 0.010056766227367299)\n",
      "test_Balanced Accuracy: 0.6814074291515972 (+/- 0.004820442593968845)\n",
      "test_Precision: 0.6826600938875172 (+/- 0.0047136019484948595)\n",
      "test_Recall: 0.682407126941382 (+/- 0.004940923150315733)\n",
      "test_F1: 0.6820287825679131 (+/- 0.004941467676553978)\n",
      "test_AUC: 0.7560156432269945 (+/- 0.00885501676805403)\n"
     ]
    }
   ],
   "source": [
    "# Definindo o modelo\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "# Definindo as métricas\n",
    "scoring = {\n",
    "    'Balanced Accuracy': make_scorer(balanced_accuracy_score),\n",
    "    'Precision': make_scorer(precision_score, average='weighted'),\n",
    "    'Recall': make_scorer(recall_score, average='weighted'),\n",
    "    'F1': make_scorer(f1_score, average='weighted'),\n",
    "    'AUC': make_scorer(roc_auc_score, needs_proba=True, average='weighted')\n",
    "}\n",
    "\n",
    "# Realizando a validação cruzada\n",
    "cv_results = cross_validate(model, X_early, y, cv=5, scoring=scoring, error_score='raise')\n",
    "\n",
    "# Extraindo os resultados\n",
    "for metric, scores in cv_results.items():\n",
    "    print(f'{metric}: {scores.mean()} (+/- {scores.std()})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>amount_events</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.770547</td>\n",
       "      <td>0.769812</td>\n",
       "      <td>0.802552</td>\n",
       "      <td>0.785782</td>\n",
       "      <td>0.856468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>3</td>\n",
       "      <td>0.759015</td>\n",
       "      <td>0.760542</td>\n",
       "      <td>0.788517</td>\n",
       "      <td>0.774224</td>\n",
       "      <td>0.846033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.752174</td>\n",
       "      <td>0.732516</td>\n",
       "      <td>0.837161</td>\n",
       "      <td>0.781278</td>\n",
       "      <td>0.843586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine (RBF Kernel)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.738800</td>\n",
       "      <td>0.735762</td>\n",
       "      <td>0.784370</td>\n",
       "      <td>0.759226</td>\n",
       "      <td>0.819975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3</td>\n",
       "      <td>0.726151</td>\n",
       "      <td>0.723779</td>\n",
       "      <td>0.774003</td>\n",
       "      <td>0.747985</td>\n",
       "      <td>0.800064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.683409</td>\n",
       "      <td>0.677268</td>\n",
       "      <td>0.762998</td>\n",
       "      <td>0.717454</td>\n",
       "      <td>0.729758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gaussian NB</td>\n",
       "      <td>3</td>\n",
       "      <td>0.517403</td>\n",
       "      <td>0.497601</td>\n",
       "      <td>0.071611</td>\n",
       "      <td>0.073152</td>\n",
       "      <td>0.722087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decission Tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.639249</td>\n",
       "      <td>0.653807</td>\n",
       "      <td>0.658533</td>\n",
       "      <td>0.656036</td>\n",
       "      <td>0.639249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model amount_events  Balanced Accuracy  \\\n",
       "4                        Random Forest             3           0.770547   \n",
       "3                             Adaboost             3           0.759015   \n",
       "5         Gradient Boosting Classifier             3           0.752174   \n",
       "1  Support Vector Machine (RBF Kernel)             3           0.738800   \n",
       "0                  Logistic Regression             3           0.726151   \n",
       "6                                  KNN             3           0.683409   \n",
       "7                          Gaussian NB             3           0.517403   \n",
       "2                       Decission Tree             3           0.639249   \n",
       "\n",
       "   Precision    Recall  F1-Score       auc  \n",
       "4   0.769812  0.802552  0.785782  0.856468  \n",
       "3   0.760542  0.788517  0.774224  0.846033  \n",
       "5   0.732516  0.837161  0.781278  0.843586  \n",
       "1   0.735762  0.784370  0.759226  0.819975  \n",
       "0   0.723779  0.774003  0.747985  0.800064  \n",
       "6   0.677268  0.762998  0.717454  0.729758  \n",
       "7   0.497601  0.071611  0.073152  0.722087  \n",
       "2   0.653807  0.658533  0.656036  0.639249  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid_start = 11\n",
    "mid_end = 20\n",
    "\n",
    "# Criar uma lista com o nome dos eventos e seus respectivos tempos\n",
    "eventos = ['event{}'.format(i) for i in range(1, 201)]\n",
    "tempos = ['event{}time'.format(i) for i in range(1, 201)]\n",
    "\n",
    "# Filtrar apenas os eventos que aconteceram antes de 10 minutos\n",
    "eventos_mid = []\n",
    "\n",
    "for evento, tempo in zip(eventos, tempos):\n",
    "    eventos_mid.append(df[(df[tempo] >= mid_start) & (df[tempo] <= mid_end)][evento])\n",
    "\n",
    "eventos_mid.append(df[['blueTopGP','blueTopWR','blueTopKDA','blueJungleGP','blueJungleWR','blueJungleKDA','blueMidGP','blueMidWR','blueMidKDA','blueADCGP','blueADCWR','blueADCKDA','blueSupportGP','blueSupportWR','blueSupportKDA','redTopGP','redTopWR','redTopKDA','redJungleGP','redJungleWR','redJungleKDA','redMidGP','redMidWR','redMidKDA','redAdcGP','redAdcWR','redAdcKDA','redSupportGP','redSupportWR','redSupportKDA']])\n",
    "\n",
    "# Criar um novo DataFrame com os eventos que aconteceram antes de 10 minutos\n",
    "df_mid = pd.concat(eventos_mid, axis=1)\n",
    "df_mid = df_mid.fillna(0)\n",
    "df_mid = df_mid.astype(int)\n",
    "X_mid = df_mid.copy()\n",
    "\n",
    "executions = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "  X_train,X_test,y_train,y_test,scaler = preprocess_input(X_mid,y)\n",
    "  \n",
    "  models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=50000),\n",
    "    'Support Vector Machine (RBF Kernel)': SVC(C=100,gamma=0.001,kernel='rbf',max_iter=50000,probability=True),\n",
    "    'Decission Tree': DecisionTreeClassifier(),\n",
    "    'Adaboost': AdaBoostClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(max_depth=25,n_estimators=600,min_samples_split=2,min_samples_leaf=1),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(criterion='friedman_mse',learning_rate=0.025,loss='deviance',max_depth=4,max_features='log2',min_samples_leaf=8,min_samples_split=3, n_estimators=100,subsample=0.5),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=3),\n",
    "    'Gaussian NB': GaussianNB()\n",
    "  }\n",
    "\n",
    "  for name, model in models.items():\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "  scores_list = []\n",
    "\n",
    "  for name,model in models.items():    \n",
    "      scores_list.append({\n",
    "      'model': name,\n",
    "      'amount_events': '3',\n",
    "      'execution': i,\n",
    "      'Balanced Accuracy': balanced_accuracy_score(y_test,model.predict(X_test)),\n",
    "      'Precision':  precision_score(y_test,model.predict(X_test)),\n",
    "      'Recall': recall_score(y_test,model.predict(X_test)),\n",
    "      'F1-Score': f1_score(y_test,model.predict(X_test)),\n",
    "      'auc': roc_auc_score(y_test,model.predict_proba(X_test)[:,1])\n",
    "      })\n",
    "  # scores = pd.DataFrame(scores_list)\n",
    "  executions = executions.append(scores_list)\n",
    "\n",
    "avg_scores_list = []\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    avg_balanced_acc = 0\n",
    "\n",
    "    model_metrics = executions.loc[executions['model'] == name]\n",
    "    avg_balanced_acc = model_metrics['Balanced Accuracy'].sum() / len(model_metrics['Balanced Accuracy'])\n",
    "    avg_precision = model_metrics['Precision'].sum() / len(model_metrics['Precision'])\n",
    "    avg_recall = model_metrics['Recall'].sum() / len(model_metrics['Recall'])\n",
    "    avg_f_score = model_metrics['F1-Score'].sum() / len(model_metrics['F1-Score'])\n",
    "    avg_auc = model_metrics['auc'].sum() / len(model_metrics['auc'])\n",
    "\n",
    "    avg_scores_list.append({\n",
    "      'model': name,\n",
    "      'amount_events': '3',\n",
    "      'Balanced Accuracy': avg_balanced_acc,\n",
    "      'Precision': avg_precision,\n",
    "      'Recall': avg_recall,\n",
    "      'F1-Score': avg_f_score,\n",
    "      'auc': avg_auc\n",
    "      })\n",
    "avg_scores = pd.DataFrame(avg_scores_list)\n",
    "ordered_scores = avg_scores.sort_values(by='auc', ascending=False)\n",
    "best_model = avg_scores.sort_values(by='auc', ascending=False).iloc[0]['model']\n",
    "ordered_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em 77.00% de das partidas, o vencedor do mid é igual ao vencedor da partida.\n"
     ]
    }
   ],
   "source": [
    "# Definindo uma função para contar os eventos\n",
    "def contar_eventos(row):\n",
    "    azul = sum(1 for evento in row if 1 <= evento <= 21)\n",
    "    vermelho = sum(1 for evento in row if 22 <= evento <= 42)\n",
    "    return azul, vermelho\n",
    "\n",
    "def calcular_porcentagem(X, Y):\n",
    "    porcentagem = (X / Y) * 100\n",
    "    return porcentagem\n",
    "\n",
    "# Selecionando apenas as colunas que começam com 'event'\n",
    "colunas_event = [coluna for coluna in df_mid.columns if coluna.startswith('event')]\n",
    "\n",
    "# Criando as novas colunas\n",
    "df_mid['qtd_eventos_azul'], df_mid['qtd_eventos_vermelho'] = zip(*df_mid[colunas_event].apply(contar_eventos, axis=1))\n",
    "df_mid['vencedor_mid'] = df_mid.apply(lambda row: 1 if row['qtd_eventos_azul'] > row['qtd_eventos_vermelho'] else 0, axis=1)\n",
    "# Exibindo o DataFrame resultante\n",
    "df_mid = pd.concat([df_mid, y], axis=1)\n",
    "df_mid['result'] = df_mid['result'].astype(int)\n",
    "\n",
    "qtd_iguais = (df_mid['vencedor_mid'] == df_mid['result']).sum()\n",
    "resultado = calcular_porcentagem(qtd_iguais, df_mid.shape[0])\n",
    "\n",
    "print(f\"Em {resultado:.2f}% de das partidas, o vencedor do mid é igual ao vencedor da partida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time: 5.601219034194946 (+/- 0.17579902231888175)\n",
      "score_time: 0.38207206726074217 (+/- 0.005616662185516731)\n",
      "test_Balanced Accuracy: 0.7690193717898933 (+/- 0.011708720183918043)\n",
      "test_Precision: 0.7708039993575884 (+/- 0.012519135877560003)\n",
      "test_Recall: 0.7703676194981209 (+/- 0.01203457162617423)\n",
      "test_F1: 0.7699815244381265 (+/- 0.011860201959558577)\n",
      "test_AUC: 0.8513109048286791 (+/- 0.011467514591578088)\n"
     ]
    }
   ],
   "source": [
    "# Definindo o modelo\n",
    "model = RandomForestClassifier(max_depth=50, n_estimators=600, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "# Definindo as métricas\n",
    "scoring = {\n",
    "    'Balanced Accuracy': make_scorer(balanced_accuracy_score),\n",
    "    'Precision': make_scorer(precision_score, average='weighted'),\n",
    "    'Recall': make_scorer(recall_score, average='weighted'),\n",
    "    'F1': make_scorer(f1_score, average='weighted'),\n",
    "    'AUC': make_scorer(roc_auc_score, needs_proba=True, average='weighted')\n",
    "}\n",
    "\n",
    "# Realizando a validação cruzada\n",
    "cv_results = cross_validate(model, X_mid, y, cv=5, scoring=scoring, error_score='raise')\n",
    "\n",
    "# Extraindo os resultados\n",
    "for metric, scores in cv_results.items():\n",
    "    print(f'{metric}: {scores.mean()} (+/- {scores.std()})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model_obj</th>\n",
       "      <th>amount_events</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=25, max_feat...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.974810</td>\n",
       "      <td>0.985508</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>0.975168</td>\n",
       "      <td>0.993340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.957585</td>\n",
       "      <td>0.967276</td>\n",
       "      <td>0.950239</td>\n",
       "      <td>0.958652</td>\n",
       "      <td>0.987427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.958386</td>\n",
       "      <td>0.959011</td>\n",
       "      <td>0.961563</td>\n",
       "      <td>0.960255</td>\n",
       "      <td>0.985872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine (RBF Kernel)</td>\n",
       "      <td>SVC(C=100, gamma=0.001, max_iter=50000, probab...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.972986</td>\n",
       "      <td>0.976925</td>\n",
       "      <td>0.970973</td>\n",
       "      <td>0.973923</td>\n",
       "      <td>0.984842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNeighborsClassifier(n_neighbors=3)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.952439</td>\n",
       "      <td>0.938582</td>\n",
       "      <td>0.974322</td>\n",
       "      <td>0.956100</td>\n",
       "      <td>0.975293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>LogisticRegression(max_iter=50000)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.874804</td>\n",
       "      <td>0.881077</td>\n",
       "      <td>0.878947</td>\n",
       "      <td>0.879893</td>\n",
       "      <td>0.927698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decission Tree</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>3</td>\n",
       "      <td>0.920251</td>\n",
       "      <td>0.924200</td>\n",
       "      <td>0.922967</td>\n",
       "      <td>0.923528</td>\n",
       "      <td>0.920251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gaussian NB</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>3</td>\n",
       "      <td>0.516125</td>\n",
       "      <td>0.510502</td>\n",
       "      <td>0.094577</td>\n",
       "      <td>0.078879</td>\n",
       "      <td>0.903152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  \\\n",
       "4                        Random Forest   \n",
       "5         Gradient Boosting Classifier   \n",
       "3                             Adaboost   \n",
       "1  Support Vector Machine (RBF Kernel)   \n",
       "6                                  KNN   \n",
       "0                  Logistic Regression   \n",
       "2                       Decission Tree   \n",
       "7                          Gaussian NB   \n",
       "\n",
       "                                           model_obj amount_events  \\\n",
       "4  (DecisionTreeClassifier(max_depth=25, max_feat...             3   \n",
       "5  ([DecisionTreeRegressor(criterion='friedman_ms...             3   \n",
       "3  (DecisionTreeClassifier(max_depth=1, random_st...             3   \n",
       "1  SVC(C=100, gamma=0.001, max_iter=50000, probab...             3   \n",
       "6                KNeighborsClassifier(n_neighbors=3)             3   \n",
       "0                 LogisticRegression(max_iter=50000)             3   \n",
       "2                           DecisionTreeClassifier()             3   \n",
       "7                                       GaussianNB()             3   \n",
       "\n",
       "   Balanced Accuracy  Precision    Recall  F1-Score       auc  \n",
       "4           0.974810   0.985508  0.965072  0.975168  0.993340  \n",
       "5           0.957585   0.967276  0.950239  0.958652  0.987427  \n",
       "3           0.958386   0.959011  0.961563  0.960255  0.985872  \n",
       "1           0.972986   0.976925  0.970973  0.973923  0.984842  \n",
       "6           0.952439   0.938582  0.974322  0.956100  0.975293  \n",
       "0           0.874804   0.881077  0.878947  0.879893  0.927698  \n",
       "2           0.920251   0.924200  0.922967  0.923528  0.920251  \n",
       "7           0.516125   0.510502  0.094577  0.078879  0.903152  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late_start = 21\n",
    "late_end = 90\n",
    "\n",
    "# Criar uma lista com o nome dos eventos e seus respectivos tempos\n",
    "eventos = ['event{}'.format(i) for i in range(1, 201)]\n",
    "tempos = ['event{}time'.format(i) for i in range(1, 201)]\n",
    "\n",
    "# Filtrar apenas os eventos que aconteceram antes de 10 minutos\n",
    "eventos_late = []\n",
    "\n",
    "for evento, tempo in zip(eventos, tempos):\n",
    "    eventos_late.append(df[(df[tempo] >= late_start) & (df[tempo] <= late_end)][evento])\n",
    "\n",
    "eventos_late.append(df[['blueTopGP','blueTopWR','blueTopKDA','blueJungleGP','blueJungleWR','blueJungleKDA','blueMidGP','blueMidWR','blueMidKDA','blueADCGP','blueADCWR','blueADCKDA','blueSupportGP','blueSupportWR','blueSupportKDA','redTopGP','redTopWR','redTopKDA','redJungleGP','redJungleWR','redJungleKDA','redMidGP','redMidWR','redMidKDA','redAdcGP','redAdcWR','redAdcKDA','redSupportGP','redSupportWR','redSupportKDA']])\n",
    "\n",
    "# Criar um novo DataFrame com os eventos que aconteceram antes de 10 minutos\n",
    "df_late = pd.concat(eventos_late, axis=1)\n",
    "df_late = df_late.fillna(0)\n",
    "df_late = df_late.astype(int)\n",
    "X_late = df_late.copy()\n",
    "\n",
    "executions = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "  X_train,X_test,y_train,y_test,scaler = preprocess_input(X_late,y)\n",
    "  \n",
    "  models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=50000),\n",
    "    'Support Vector Machine (RBF Kernel)': SVC(C=100,gamma=0.001,kernel='rbf',max_iter=50000,probability=True),\n",
    "    'Decission Tree': DecisionTreeClassifier(),\n",
    "    'Adaboost': AdaBoostClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(max_depth=25,n_estimators=600,min_samples_split=2,min_samples_leaf=1),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(criterion='friedman_mse',learning_rate=0.025,loss='deviance',max_depth=4,max_features='log2',min_samples_leaf=8,min_samples_split=3, n_estimators=100,subsample=0.5),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=3),\n",
    "    'Gaussian NB': GaussianNB()\n",
    "  }\n",
    "\n",
    "  for name, model in models.items():\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "  scores_list = []\n",
    "\n",
    "  for name,model in models.items():    \n",
    "      scores_list.append({\n",
    "      'model': name,\n",
    "      'model_obj': model,\n",
    "      'amount_events': '3',\n",
    "      'execution': i,\n",
    "      'Balanced Accuracy': balanced_accuracy_score(y_test,model.predict(X_test)),\n",
    "      'Precision':  precision_score(y_test,model.predict(X_test)),\n",
    "      'Recall': recall_score(y_test,model.predict(X_test)),\n",
    "      'F1-Score': f1_score(y_test,model.predict(X_test)),\n",
    "      'auc': roc_auc_score(y_test,model.predict_proba(X_test)[:,1])\n",
    "      })\n",
    "  # scores = pd.DataFrame(scores_list)\n",
    "  executions = executions.append(scores_list)\n",
    "\n",
    "avg_scores_list = []\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    avg_balanced_acc = 0\n",
    "\n",
    "    model_metrics = executions.loc[executions['model'] == name]\n",
    "    avg_balanced_acc = model_metrics['Balanced Accuracy'].sum() / len(model_metrics['Balanced Accuracy'])\n",
    "    avg_precision = model_metrics['Precision'].sum() / len(model_metrics['Precision'])\n",
    "    avg_recall = model_metrics['Recall'].sum() / len(model_metrics['Recall'])\n",
    "    avg_f_score = model_metrics['F1-Score'].sum() / len(model_metrics['F1-Score'])\n",
    "    avg_auc = model_metrics['auc'].sum() / len(model_metrics['auc'])\n",
    "\n",
    "    avg_scores_list.append({\n",
    "      'model': name,\n",
    "      'model_obj': model,\n",
    "      'amount_events': '3',\n",
    "      'Balanced Accuracy': avg_balanced_acc,\n",
    "      'Precision': avg_precision,\n",
    "      'Recall': avg_recall,\n",
    "      'F1-Score': avg_f_score,\n",
    "      'auc': avg_auc\n",
    "      })\n",
    "avg_scores = pd.DataFrame(avg_scores_list)\n",
    "ordered_scores = avg_scores.sort_values(by='auc', ascending=False)\n",
    "best_model = avg_scores.sort_values(by='auc', ascending=False).iloc[0]['model_obj']\n",
    "ordered_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em 97.81% de das partidas, o vencedor do late é igual ao vencedor da partida.\n"
     ]
    }
   ],
   "source": [
    "# Definindo uma função para contar os eventos\n",
    "def contar_eventos(row):\n",
    "    azul = sum(1 for evento in row if 1 <= evento <= 21)\n",
    "    vermelho = sum(1 for evento in row if 22 <= evento <= 42)\n",
    "    return azul, vermelho\n",
    "\n",
    "def calcular_porcentagem(X, Y):\n",
    "    porcentagem = (X / Y) * 100\n",
    "    return porcentagem\n",
    "\n",
    "# Selecionando apenas as colunas que começam com 'event'\n",
    "colunas_event = [coluna for coluna in df_late.columns if coluna.startswith('event')]\n",
    "\n",
    "# Criando as novas colunas\n",
    "df_late['qtd_eventos_azul'], df_late['qtd_eventos_vermelho'] = zip(*df_late[colunas_event].apply(contar_eventos, axis=1))\n",
    "df_late['vencedor_late'] = df_late.apply(lambda row: 1 if row['qtd_eventos_azul'] > row['qtd_eventos_vermelho'] else 0, axis=1)\n",
    "# Exibindo o DataFrame resultante\n",
    "df_late = pd.concat([df_late, y], axis=1)\n",
    "df_late['result'] = df_late['result'].astype(int)\n",
    "\n",
    "qtd_iguais = (df_late['vencedor_late'] == df_late['result']).sum()\n",
    "resultado = calcular_porcentagem(qtd_iguais, df_late.shape[0])\n",
    "\n",
    "print(f\"Em {resultado:.2f}% das partidas, o vencedor do late é igual ao vencedor da partida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time: 5.015894794464112 (+/- 0.23099545667559607)\n",
      "score_time: 0.3372201442718506 (+/- 0.03896682310915093)\n",
      "test_Balanced Accuracy: 0.9766482087875292 (+/- 0.005384925936980041)\n",
      "test_Precision: 0.9765530133847516 (+/- 0.00540035467899779)\n",
      "test_Recall: 0.9762209838686701 (+/- 0.005434627920208715)\n",
      "test_F1: 0.9762284973835884 (+/- 0.005432235453615175)\n",
      "test_AUC: 0.9953144910581837 (+/- 0.002953649668429816)\n"
     ]
    }
   ],
   "source": [
    "# Definindo o modelo\n",
    "model = RandomForestClassifier(max_depth=50, n_estimators=600, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "# Definindo as métricas\n",
    "scoring = {\n",
    "    'Balanced Accuracy': make_scorer(balanced_accuracy_score),\n",
    "    'Precision': make_scorer(precision_score, average='weighted'),\n",
    "    'Recall': make_scorer(recall_score, average='weighted'),\n",
    "    'F1': make_scorer(f1_score, average='weighted'),\n",
    "    'AUC': make_scorer(roc_auc_score, needs_proba=True, average='weighted')\n",
    "}\n",
    "\n",
    "# Realizando a validação cruzada\n",
    "cv_results = cross_validate(model, X_late, y, cv=5, scoring=scoring, error_score='raise')\n",
    "\n",
    "# Extraindo os resultados\n",
    "for metric, scores in cv_results.items():\n",
    "    print(f'{metric}: {scores.mean()} (+/- {scores.std()})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>event46</td>\n",
       "      <td>0.047115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>event48</td>\n",
       "      <td>0.044633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>event45</td>\n",
       "      <td>0.042999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>event47</td>\n",
       "      <td>0.039119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>event50</td>\n",
       "      <td>0.036110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>event49</td>\n",
       "      <td>0.033093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>event51</td>\n",
       "      <td>0.032792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>event44</td>\n",
       "      <td>0.032312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>event56</td>\n",
       "      <td>0.031655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>event43</td>\n",
       "      <td>0.029614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>event53</td>\n",
       "      <td>0.029413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>event42</td>\n",
       "      <td>0.027817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>event52</td>\n",
       "      <td>0.026768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>event54</td>\n",
       "      <td>0.026332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>event41</td>\n",
       "      <td>0.026217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>event55</td>\n",
       "      <td>0.026128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>event40</td>\n",
       "      <td>0.025619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>event57</td>\n",
       "      <td>0.024378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>event60</td>\n",
       "      <td>0.020554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>event59</td>\n",
       "      <td>0.020142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature  Importance\n",
       "45  event46    0.047115\n",
       "47  event48    0.044633\n",
       "44  event45    0.042999\n",
       "46  event47    0.039119\n",
       "49  event50    0.036110\n",
       "48  event49    0.033093\n",
       "50  event51    0.032792\n",
       "43  event44    0.032312\n",
       "55  event56    0.031655\n",
       "42  event43    0.029614\n",
       "52  event53    0.029413\n",
       "41  event42    0.027817\n",
       "51  event52    0.026768\n",
       "53  event54    0.026332\n",
       "40  event41    0.026217\n",
       "54  event55    0.026128\n",
       "39  event40    0.025619\n",
       "56  event57    0.024378\n",
       "59  event60    0.020554\n",
       "58  event59    0.020142"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtendo a importância das características\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "# Criando um DataFrame para visualizar as importâncias\n",
    "importance_df = pd.DataFrame({'Feature': X_late.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Ordenando as características pela importância\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Visualizando as 10 características mais importantes\n",
    "importance_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cinco valores mais frequentes em event45:\n",
      "BLUE: kill           1448\n",
      "RED: kill            1410\n",
      "BLUE: nexus_tower     192\n",
      "BLUE: dragon          160\n",
      "RED: dragon           156\n",
      "Name: event45, dtype: int64\n",
      "==============================\n",
      "Cinco valores mais frequentes em event46:\n",
      "BLUE: kill           1487\n",
      "RED: kill            1326\n",
      "BLUE: nexus_tower     183\n",
      "RED: nexus_tower      176\n",
      "BLUE: dragon          150\n",
      "Name: event46, dtype: int64\n",
      "==============================\n",
      "Cinco valores mais frequentes em event47:\n",
      "BLUE: kill           1449\n",
      "RED: kill            1304\n",
      "BLUE: nexus_tower     219\n",
      "RED: nexus_tower      184\n",
      "BLUE: dragon          138\n",
      "Name: event47, dtype: int64\n",
      "==============================\n",
      "Cinco valores mais frequentes em event48:\n",
      "BLUE: kill           1348\n",
      "RED: kill            1320\n",
      "BLUE: nexus_tower     228\n",
      "RED: nexus_tower      193\n",
      "BLUE: dragon          127\n",
      "Name: event48, dtype: int64\n",
      "==============================\n",
      "Cinco valores mais frequentes em event44:\n",
      "BLUE: kill           1462\n",
      "RED: kill            1425\n",
      "BLUE: nexus_tower     194\n",
      "BLUE: dragon          166\n",
      "RED: dragon           165\n",
      "Name: event44, dtype: int64\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3170: DtypeWarning: Columns (116,117,118,119,120,121,122,123,124,125,126,127) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_eventos = pd.read_csv('../../data/crawler/unified-events-statistics-with-kills.csv')\n",
    "\n",
    "colunas = ['event45', 'event46', 'event47', 'event48', 'event44']  # Substitua com os nomes das suas colunas\n",
    "\n",
    "for coluna in colunas:\n",
    "    contagem = df_eventos[coluna].value_counts().head(5)  # Obtém as três maiores contagens\n",
    "    print(f\"Cinco valores mais frequentes em {coluna}:\")\n",
    "    print(contagem)\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cinco valores mais frequentes em event45time:\n",
      "26.0    466\n",
      "27.0    458\n",
      "28.0    445\n",
      "29.0    437\n",
      "30.0    409\n",
      "Name: event45time, dtype: int64\n",
      "==============================\n",
      "Cinco valores mais frequentes em event46time:\n",
      "29.0    457\n",
      "28.0    456\n",
      "27.0    452\n",
      "26.0    433\n",
      "30.0    391\n",
      "Name: event46time, dtype: int64\n",
      "==============================\n",
      "Cinco valores mais frequentes em event47time:\n",
      "29.0    463\n",
      "28.0    456\n",
      "27.0    450\n",
      "30.0    389\n",
      "26.0    383\n",
      "Name: event47time, dtype: int64\n",
      "==============================\n",
      "Cinco valores mais frequentes em event48time:\n",
      "29.0    453\n",
      "28.0    446\n",
      "27.0    433\n",
      "30.0    382\n",
      "26.0    358\n",
      "Name: event48time, dtype: int64\n",
      "==============================\n",
      "Cinco valores mais frequentes em event44time:\n",
      "27.0    465\n",
      "26.0    457\n",
      "29.0    446\n",
      "28.0    444\n",
      "25.0    431\n",
      "Name: event44time, dtype: int64\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "df_eventos = pd.read_csv('../../data/crawler/unified-events-statistics-with-kills.csv')\n",
    "\n",
    "colunas = ['event45time', 'event46time', 'event47time', 'event48time', 'event44time']  # Substitua com os nomes das suas colunas\n",
    "\n",
    "for coluna in colunas:\n",
    "    contagem = df_eventos[coluna].value_counts().head(5)  # Obtém as três maiores contagens\n",
    "    print(f\"Cinco valores mais frequentes em {coluna}:\")\n",
    "    print(contagem)\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testes realizados com 1203 partidas.\n",
      "Acurácia: 0.970074812967581\n",
      "AUC: 0.9924726984759878\n",
      "O resultado era 0 e o previsto foi 1\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 0 e o previsto foi 1\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 0 e o previsto foi 1\n",
      "O resultado era 0 e o previsto foi 1\n",
      "O resultado era 0 e o previsto foi 1\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 0 e o previsto foi 1\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 0 e o previsto foi 1\n",
      "O resultado era 0 e o previsto foi 1\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 0 e o previsto foi 1\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 0 e o previsto foi 1\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 0 e o previsto foi 1\n",
      "O resultado era 1 e o previsto foi 0\n",
      "O resultado era 0 e o previsto foi 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "partidas_erradas = y_test[y_test != y_pred].index.tolist()\n",
    "\n",
    "print('Testes realizados com ' + str(len(y_test)) + ' partidas.')\n",
    "print('Acurácia: ' + str(accuracy))\n",
    "print('AUC: ' + str(auc))\n",
    "for index in partidas_erradas:\n",
    "    print('O resultado era ' + str(y_test[index]) + ' e o previsto foi ' + str(y_pred[index]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

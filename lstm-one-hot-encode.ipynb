{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dict = {\n",
    "    'BLUE: first_blood': 0,\n",
    "    'BLUE: dragon': 1,\n",
    "    'BLUE: herald': 2,\n",
    "    'BLUE: first_tower_top': 3,\n",
    "    'BLUE: first_tower_mid': 4,\n",
    "    'BLUE: first_tower_bot': 5,\n",
    "    'BLUE: second_tower_top': 6,\n",
    "    'BLUE: second_tower_mid': 7,\n",
    "    'BLUE: second_tower_bot': 8,\n",
    "    'BLUE: third_tower_top': 9,\n",
    "    'BLUE: third_tower_mid': 10,\n",
    "    'BLUE: third_tower_bot': 11,\n",
    "    'BLUE: inhibitor_top': 12,\n",
    "    'BLUE: inhibitor_mid': 13,\n",
    "    'BLUE: inhibitor_bot': 14,\n",
    "    'BLUE: baron': 15,\n",
    "    'BLUE: elder_dragon': 16,\n",
    "    'BLUE: nexus_tower': 17,\n",
    "    'BLUE: nexus': 18,\n",
    "    'RED: first_blood': 19,\n",
    "    'RED: dragon': 20,\n",
    "    'RED: herald': 21,\n",
    "    'RED: first_tower_top': 22,\n",
    "    'RED: first_tower_mid': 23,\n",
    "    'RED: first_tower_bot': 24,\n",
    "    'RED: second_tower_top': 25,\n",
    "    'RED: second_tower_mid': 26,\n",
    "    'RED: second_tower_bot': 27,\n",
    "    'RED: third_tower_top': 28,\n",
    "    'RED: third_tower_mid': 29,\n",
    "    'RED: third_tower_bot': 30,\n",
    "    'RED: inhibitor_top': 31,\n",
    "    'RED: inhibitor_mid': 32,\n",
    "    'RED: inhibitor_bot': 33,\n",
    "    'RED: baron': 34,\n",
    "    'RED: elder_dragon': 35,\n",
    "    'RED: nexus_tower': 36,\n",
    "    'RED: nexus': 37\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/clean-one-line.csv')\n",
    "df = df.drop('game', axis=1)\n",
    "data = df.values.tolist()\n",
    "\n",
    "for game in data:\n",
    "    for i, s in enumerate(game):\n",
    "            game[i] = s\n",
    "\n",
    "dataArray = []\n",
    "\n",
    "for game in data:\n",
    "    dataArray += game\n",
    "\n",
    "dataArray = [b for b in dataArray if not(isinstance(b, float))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/clean-one-line.csv')\n",
    "df = df.drop('game', axis=1)\n",
    "data = df.values.tolist()\n",
    "\n",
    "for game in data:\n",
    "    for i, s in enumerate(game):\n",
    "        if s in events_dict:\n",
    "            game[i] = events_dict.get(s)\n",
    "\n",
    "labelsArray = []\n",
    "\n",
    "for game in data:\n",
    "    labelsArray += game\n",
    "\n",
    "sequence = [b for b in labelsArray if not(isinstance(b, float))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    " \n",
    "# generate a sequence of random numbers in [0, 99]\n",
    "def generate_sequence():\n",
    "\tfinalNum = randint(25, 6996)\n",
    "\tstartNum = finalNum - 25\n",
    "\treturn sequence[startNum:finalNum]\n",
    " \n",
    "# one hot encode sequence\n",
    "def one_hot_encode(sequence, n_unique=38):\n",
    "\tencoding = list()\n",
    "\tfor value in sequence:\n",
    "\t\tvector = [0 for _ in range(n_unique)]\n",
    "\t\tvector[value] = 1\n",
    "\t\tencoding.append(vector)\n",
    "\treturn array(encoding)\n",
    " \n",
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "\treturn [argmax(vector) for vector in encoded_seq]\n",
    " \n",
    "# convert encoded sequence to supervised learning\n",
    "def to_supervised(sequence, n_in, n_out):\n",
    "\t# create lag copies of the sequence\n",
    "\tdf = DataFrame(sequence)\n",
    "\tdf = concat([df.shift(n_in-i-1) for i in range(n_in)], axis=1)\n",
    "\t# drop rows with missing values\n",
    "\tdf.dropna(inplace=True)\n",
    "\t# specify columns for input and output pairs\n",
    "\tvalues = df.values\n",
    "\twidth = sequence.shape[1]\n",
    "\tX = values.reshape(len(values), n_in, width)\n",
    "\ty = values[:, -:(n_out*width)].reshape(len(values), n_out, width)\n",
    "\treturn X, y\n",
    " \n",
    "# prepare data for the LSTM\n",
    "def get_data(n_in, n_out, sequence = []):\n",
    "\t# generate random sequence\n",
    "\tif not len(sequence):\n",
    "\t\tsequence = generate_sequence()\n",
    "\t# one hot encode\n",
    "\tencoded = one_hot_encode(sequence)\n",
    "\t# convert to X,y pairs\n",
    "\tX,y = to_supervised(encoded, n_in, n_out)\n",
    "\treturn X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Expected: [25, 28] Predicted [25, 28]\n",
      "Expected: [28, 31] Predicted [28, 31]\n",
      "Expected: [31, 26] Predicted [31, 26]\n",
      "Expected: [26, 29] Predicted [26, 29]\n",
      "Expected: [29, 32] Predicted [29, 32]\n",
      "Expected: [32, 36] Predicted [32, 36]\n",
      "Expected: [36, 16] Predicted [36, 16]\n",
      "Expected: [16, 36] Predicted [16, 36]\n",
      "Expected: [36, 15] Predicted [36, 15]\n",
      "Expected: [15, 10] Predicted [15, 10]\n",
      "Expected: [10, 32] Predicted [10, 32]\n",
      "Expected: [32, 37] Predicted [32, 37]\n",
      "Expected: [37, 21] Predicted [37, 21]\n",
      "Expected: [21, 0] Predicted [21, 0]\n",
      "Expected: [0, 1] Predicted [0, 1]\n",
      "Expected: [1, 5] Predicted [1, 5]\n",
      "Expected: [5, 22] Predicted [5, 22]\n",
      "Expected: [22, 8] Predicted [22, 8]\n",
      "Expected: [8, 23] Predicted [8, 23]\n",
      "Expected: [23, 1] Predicted [23, 1]\n",
      "Expected: [1, 3] Predicted [1, 3]\n"
     ]
    }
   ],
   "source": [
    "# define LSTM\n",
    "n_in = 5\n",
    "n_out = 2\n",
    "encoded_length = 38\n",
    "batch_size = 21\n",
    "model = Sequential()\n",
    "model.add(LSTM(150, batch_input_shape=(batch_size, n_in, encoded_length), stateful=True))\n",
    "model.add(RepeatVector(n_out))\n",
    "model.add(LSTM(150, return_sequences=True, stateful=True))\n",
    "model.add(TimeDistributed(Dense(encoded_length, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# train LSTM\n",
    "for epoch in range(5000):\n",
    "\t# generate new random sequence\n",
    "\tX,y = get_data(n_in, n_out)\n",
    "\t# fit model for one epoch on this sequence\n",
    "\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\tmodel.reset_states()\n",
    "\n",
    "# evaluate LSTM\n",
    "X,y = get_data(n_in, n_out)\n",
    "yhat = model.predict(X, batch_size=batch_size, verbose=1)\n",
    "# decode all pairs\n",
    "for i in range(len(X)):\n",
    "\tprint('Expected:', one_hot_decode(y[i]), 'Predicted', one_hot_decode(yhat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential_10',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (21, 5, 38),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'lstm_20_input'}},\n",
       "  {'class_name': 'LSTM',\n",
       "   'config': {'name': 'lstm_20',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (21, 5, 38),\n",
       "    'dtype': 'float32',\n",
       "    'return_sequences': False,\n",
       "    'return_state': False,\n",
       "    'go_backwards': False,\n",
       "    'stateful': True,\n",
       "    'unroll': False,\n",
       "    'time_major': False,\n",
       "    'units': 150,\n",
       "    'activation': 'tanh',\n",
       "    'recurrent_activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'recurrent_initializer': {'class_name': 'Orthogonal',\n",
       "     'config': {'gain': 1.0, 'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'unit_forget_bias': True,\n",
       "    'kernel_regularizer': None,\n",
       "    'recurrent_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'recurrent_constraint': None,\n",
       "    'bias_constraint': None,\n",
       "    'dropout': 0.0,\n",
       "    'recurrent_dropout': 0.0,\n",
       "    'implementation': 2}},\n",
       "  {'class_name': 'RepeatVector',\n",
       "   'config': {'name': 'repeat_vector_10',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'n': 2}},\n",
       "  {'class_name': 'LSTM',\n",
       "   'config': {'name': 'lstm_21',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'return_sequences': True,\n",
       "    'return_state': False,\n",
       "    'go_backwards': False,\n",
       "    'stateful': True,\n",
       "    'unroll': False,\n",
       "    'time_major': False,\n",
       "    'units': 150,\n",
       "    'activation': 'tanh',\n",
       "    'recurrent_activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'recurrent_initializer': {'class_name': 'Orthogonal',\n",
       "     'config': {'gain': 1.0, 'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'unit_forget_bias': True,\n",
       "    'kernel_regularizer': None,\n",
       "    'recurrent_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'recurrent_constraint': None,\n",
       "    'bias_constraint': None,\n",
       "    'dropout': 0.0,\n",
       "    'recurrent_dropout': 0.0,\n",
       "    'implementation': 2}},\n",
       "  {'class_name': 'TimeDistributed',\n",
       "   'config': {'name': 'time_distributed_10',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'layer': {'class_name': 'Dense',\n",
       "     'config': {'name': 'dense_10',\n",
       "      'trainable': True,\n",
       "      'dtype': 'float32',\n",
       "      'units': 38,\n",
       "      'activation': 'softmax',\n",
       "      'use_bias': True,\n",
       "      'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "       'config': {'seed': None}},\n",
       "      'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "      'kernel_regularizer': None,\n",
       "      'bias_regularizer': None,\n",
       "      'activity_regularizer': None,\n",
       "      'kernel_constraint': None,\n",
       "      'bias_constraint': None}}}}]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11bbcf57d79407485a8d65c6cc737ca9d49c6f1d1b34c1ae2a5e6f49b42ea89b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

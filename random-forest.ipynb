{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dict = {\n",
    "    'BLUE: first_blood': 0,\n",
    "    'BLUE: dragon': 1,\n",
    "    'BLUE: herald': 2,\n",
    "    'BLUE: first_tower_top': 3,\n",
    "    'BLUE: first_tower_mid': 4,\n",
    "    'BLUE: first_tower_bot': 5,\n",
    "    'BLUE: second_tower_top': 6,\n",
    "    'BLUE: second_tower_mid': 7,\n",
    "    'BLUE: second_tower_bot': 8,\n",
    "    'BLUE: third_tower_top': 9,\n",
    "    'BLUE: third_tower_mid': 10,\n",
    "    'BLUE: third_tower_bot': 11,\n",
    "    'BLUE: inhibitor_top': 12,\n",
    "    'BLUE: inhibitor_mid': 13,\n",
    "    'BLUE: inhibitor_bot': 14,\n",
    "    'BLUE: baron': 15,\n",
    "    'BLUE: elder_dragon': 16,\n",
    "    'BLUE: nexus_tower': 17,\n",
    "    'BLUE: nexus': 18,\n",
    "    'RED: first_blood': 19,\n",
    "    'RED: dragon': 20,\n",
    "    'RED: herald': 21,\n",
    "    'RED: first_tower_top': 22,\n",
    "    'RED: first_tower_mid': 23,\n",
    "    'RED: first_tower_bot': 24,\n",
    "    'RED: second_tower_top': 25,\n",
    "    'RED: second_tower_mid': 26,\n",
    "    'RED: second_tower_bot': 27,\n",
    "    'RED: third_tower_top': 28,\n",
    "    'RED: third_tower_mid': 29,\n",
    "    'RED: third_tower_bot': 30,\n",
    "    'RED: inhibitor_top': 31,\n",
    "    'RED: inhibitor_mid': 32,\n",
    "    'RED: inhibitor_bot': 33,\n",
    "    'RED: baron': 34,\n",
    "    'RED: elder_dragon': 35,\n",
    "    'RED: nexus_tower': 36,\n",
    "    'RED: nexus': 37\n",
    "}\n",
    "\n",
    "n_in = 19\n",
    "df = pd.read_csv('data/clean-one-line.csv')\n",
    "df = df.drop('golId', axis=1)\n",
    "data = df.values.tolist()\n",
    "\n",
    "for game in data:\n",
    "    for i, s in enumerate(game):\n",
    "        if s in events_dict:\n",
    "            game[i] = events_dict.get(s)\n",
    "\n",
    "sequence = [b for b in data if not(isinstance(b, float))]\n",
    "sequence = [[x for x in y if not np.isnan(x)] for y in sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSequence(games, n_steps_in, n_steps_out=1):\n",
    "    X, Y = [], []\n",
    "    \n",
    "    for sequence in games:\n",
    "        for i in range(len(sequence)):\n",
    "            # find the end of this pattern\n",
    "            end_ix = i + n_steps_in\n",
    "            out_end_ix = end_ix + n_steps_out\n",
    "            # check if we are beyond the sequence\n",
    "            if out_end_ix > len(sequence):\n",
    "                break\n",
    "            # gather input and output parts of the pattern\n",
    "            seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "            X.append(seq_x)\n",
    "            Y.append(seq_y)\n",
    "\t\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2792"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test = train_test_split(sequence,test_size=0.15,random_state=42,shuffle=False)\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, y_train = splitSequence(x_train, n_in)\n",
    "test, y_test = splitSequence(x_test, n_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({'event_1': [],\n",
    "                   'event_2': [],\n",
    "                   'event_3': [],\n",
    "                   'event_4': [],\n",
    "                   'event_5': [],\n",
    "                   'event_6': [],\n",
    "                   'target': []})\n",
    "\n",
    "df_train = pd.DataFrame({'event_1': [],\n",
    "                   'event_2': [],\n",
    "                   'event_3': [],\n",
    "                   'event_4': [],\n",
    "                   'event_5': [],\n",
    "                   'event_6': [],\n",
    "                   'target': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    17.0\n",
       "1    10.0\n",
       "2    17.0\n",
       "3    18.0\n",
       "4    37.0\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index,test_row in enumerate(test):\n",
    "    event_1 = test_row[0]\n",
    "    event_2 = test_row[1]\n",
    "    event_3 = test_row[2]\n",
    "    event_4 = test_row[3]\n",
    "    event_5 = test_row[4]\n",
    "    event_6 = test_row[5]\n",
    "    df_test.loc[len(df_test.index)] = [event_1, event_2, event_3, event_4, event_5, event_6, y_test[index][0]]\n",
    "\n",
    "y_test = df_test['target'].copy()\n",
    "X_test = df_test.drop(['target'],axis=1)\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, train_row in enumerate(train):\n",
    "    event_1 = train_row[0]\n",
    "    event_2 = train_row[1]\n",
    "    event_3 = train_row[2]\n",
    "    event_4 = train_row[3]\n",
    "    event_5 = train_row[4]\n",
    "    event_6 = train_row[5]\n",
    "    df_train.loc[len(df_train.index)] = [event_1, event_2, event_3, event_4, event_5, event_6, y_train[index][0]]\n",
    "\n",
    "y_train = df_train['target'].copy()\n",
    "X_train = df_train.drop(['target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14331"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2443"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, min_samples_leaf=4, min_samples_split=10,\n",
       "                       n_estimators=295)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=295, min_samples_leaf=4,min_samples_split=10,max_depth=5, criterion='gini', bootstrap=True)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model score: 0.21673295652780686\n",
      "test model score: 0.21162505116659844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        63\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         4.0       0.00      0.00      0.00         4\n",
      "         5.0       0.00      0.00      0.00         3\n",
      "         6.0       0.00      0.00      0.00        26\n",
      "         7.0       0.00      0.00      0.00        27\n",
      "         8.0       0.00      0.00      0.00        29\n",
      "         9.0       0.00      0.00      0.00        43\n",
      "        10.0       0.00      0.00      0.00        75\n",
      "        11.0       0.00      0.00      0.00        55\n",
      "        12.0       0.00      0.00      0.00        50\n",
      "        13.0       0.00      0.00      0.00       121\n",
      "        14.0       0.00      0.00      0.00        77\n",
      "        15.0       0.00      0.00      0.00        52\n",
      "        16.0       0.00      0.00      0.00        18\n",
      "        17.0       0.23      0.69      0.35       392\n",
      "        18.0       0.00      0.00      0.00       243\n",
      "        20.0       0.00      0.00      0.00        48\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "        23.0       0.00      0.00      0.00         5\n",
      "        24.0       0.00      0.00      0.00         3\n",
      "        25.0       0.00      0.00      0.00        28\n",
      "        26.0       0.00      0.00      0.00        30\n",
      "        27.0       0.00      0.00      0.00        26\n",
      "        28.0       0.00      0.00      0.00        50\n",
      "        29.0       0.00      0.00      0.00        56\n",
      "        30.0       0.00      0.00      0.00        47\n",
      "        31.0       0.00      0.00      0.00        65\n",
      "        32.0       0.00      0.00      0.00       101\n",
      "        33.0       0.00      0.00      0.00        81\n",
      "        34.0       0.00      0.00      0.00        64\n",
      "        35.0       0.00      0.00      0.00        31\n",
      "        36.0       0.19      0.73      0.30       331\n",
      "        37.0       0.23      0.03      0.05       196\n",
      "\n",
      "    accuracy                           0.21      2443\n",
      "   macro avg       0.02      0.04      0.02      2443\n",
      "weighted avg       0.08      0.21      0.10      2443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\linco\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(f'training model score: {clf.score(X_train, y_train)}')\n",
    "print(f'test model score: {clf.score(X_test, y_test)}')\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>event_5</th>\n",
       "      <td>0.236832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_6</th>\n",
       "      <td>0.235211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_4</th>\n",
       "      <td>0.198230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_3</th>\n",
       "      <td>0.144550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_2</th>\n",
       "      <td>0.093925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_1</th>\n",
       "      <td>0.091252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "event_5  0.236832\n",
       "event_6  0.235211\n",
       "event_4  0.198230\n",
       "event_3  0.144550\n",
       "event_2  0.093925\n",
       "event_1  0.091252"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.feature_importances_, index=X_train.columns).sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "estimator = clf.estimators_[5]\n",
    "\n",
    "\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = ['event_1','event_2','event_3','event_4','event_5','event_6'],\n",
    "                class_names = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38'],\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "os.system('dot -Tpng tree.dot -o random.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11bbcf57d79407485a8d65c6cc737ca9d49c6f1d1b34c1ae2a5e6f49b42ea89b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
